---
- name: set karmada_cluster_phase
  set_fact:
    karmada_cluster_phase: "existing"
  when: karmada_apiserver_deploy|length > 0

- block:

  - name: Set status karmada Creating
    vars:
      karmada_status: "Creating"
    k8s_status:
      api_version: operator.karmada.io/v1alpha1
      kind: KarmadaDeployment
      name: "{{ karmada_cluster_name }}"
      namespace: "{{ karmada_namespace }}"
      status: "{{ lookup('template', 'status.yaml') | from_yaml }}"

  - name: Create '{{ karmada_controlplane_manifests }}' directory
    file:
      path: "{{ karmada_controlplane_manifests }}"
      state: directory
      mode: 0700

  - name: copy template service account, cluster role for controller-manager
    template:
      src: "{{ item.file }}"
      dest: "{{ karmada_controlplane_manifests }}/{{ item.file }}"
    with_items:
      - { name: clusterrole, file: clusterrole.yaml, type: clusterrole }
      - { name: clusterrolebinding, file: clusterrolebinding.yaml, type: clusterrolebinding }
      - { name: serviceaccount, file: serviceaccount.yaml, type: sa }
    register: karmada_rbac_manifests

  - name: create sa, cluster role for controller-manager
    shell: "{{ bin_dir }}/kubectl apply -f {{ karmada_controlplane_manifests }}/{{ item.item.file }}"  # noqa 301 306 303 305
    ignore_errors: true
    with_items: "{{ karmada_rbac_manifests.results }}"

  - name: copy template karmada-apiserver,kube-controller-manager,karmada-aggregated-apiserver,karmada-search
    template:
      src: "{{ item.file }}"
      dest: "{{ karmada_controlplane_manifests }}/{{ item.file }}"
    with_items:
      - { name: apiserver, file: karmada-apiserver.yaml, type: deployment }
      - { name: controller-manager, file: kube-controller-manager.yaml, type: deployment }
      - { name: aggregated-apiserver, file: karmada-aggregated-apiserver.yaml, type: deployment }
      - { name: search, file: karmada-search.yaml, type: deployment }
    register: karmada_v1_manifests

  - name: Start karmada-apiserver,kube-controller-manager,karmada-aggregated-apiserver,karmada-search
    shell: "{{ bin_dir }}/kubectl apply -f {{ karmada_controlplane_manifests }}/{{ item.item.file }}"  # noqa 301 306 303 305
    ignore_errors: true
    with_items: "{{ karmada_v1_manifests.results }}"

  - name: Waiting for apiserver to running
    uri:
      url: "https://karmada-apiserver.{{ karmada_namespace }}.svc.{{ cluster_domain }}:5443/healthz"
      validate_certs: no
    register: apiserver_result
    until: apiserver_result.status == 200
    retries: 60
    delay: 5

  - name: create namespace karmada-system on karmada apiserver
    shell: "{{ bin_dir }}/kubectl create ns {{ karmada_namespace }} --kubeconfig={{ karmada_config }}"  # noqa 301 306 303 305
    ignore_errors: true

  - name: copy crds to ansilbe operator pod
    copy:
      src: "{{ karmada_version }}_crds"
      dest: "{{ karmada_crd_dir }}"
      mode: 0700
    run_once: yes

  - name: add ca.crt to crds on operator pod
    shell: >
      ca_string=$(cat {{ karmada_ca_crt_filename }} | base64 | tr "\n" " "|sed s/[[:space:]]//g) &&
      sed -i'' -e "s/k_caB/${ca_string}/g" "{{ karmada_crd_dir }}/{{ karmada_version }}_crds/patches/webhook_in_clusterresourcebindings.yaml" &&
      sed -i'' -e "s/k_caB/${ca_string}/g" "{{ karmada_crd_dir }}/{{ karmada_version }}_crds/patches/webhook_in_resourcebindings.yaml"

  - name: create crds on karmada-apiserver
    shell: "kubectl --kubeconfig={{ karmada_config }} kustomize {{ karmada_crd_dir }}/{{ karmada_version }}_crds | kubectl --kubeconfig={{ karmada_config }} apply -f -"  # noqa 301 303 305 306

  - name: copy template webhook-configuration、aggregated-apiserver-apiservice、search-apiservice、cluster-proxy-admin-rbac to operator pod
    template:
      src: "{{ item.file }}"
      dest: "{{ karmada_controlplane_manifests }}/{{ item.file }}"
    with_items:
      - { name: webhook, file: webhook-configuration.yaml, type: MutatingWebhookConfiguration }
      - { name: aa-svc, file: karmada-aggregated-apiserver-apiservice.yaml, type: Service }
      - { name: ssearch-svc, file: karmada-search-apiservice.yaml, type: Service }
      - { name: rbac, file: cluster-proxy-admin-rbac.yaml, type: RBAC }
    register: karmada_manifests

  - name: create webhook-configuration、aggregated-apiserver-apiservice、search-apiservice、cluster-proxy-admin-rbac on karmada apiserver
    shell: "{{ bin_dir }}/kubectl --kubeconfig={{ karmada_config }} apply -f {{ karmada_controlplane_manifests }}/{{ item.item.file }}"  # noqa 301 306 303 305
    ignore_errors: true
    with_items: "{{ karmada_manifests.results }}"

  - name: copy template karmada shceduler, descheduler, webhook and  controller manager
    template:
      src: "{{ item.file }}"
      dest: "{{ karmada_controlplane_manifests }}/{{ item.file }}"
    with_items:
      - { name: manager, file: karmada-controller-manager.yaml, type: deployment }
      - { name: scheduler, file: karmada-scheduler.yaml, type: deployment }
      - { name: descheduler, file: karmada-descheduler.yaml, type: deployment }
      - { name: webhook, file: karmada-webhook.yaml, type: deployment }
    register: karmada_host_manifests

  - name: start karmada scheduler, descheduler,webhook and karmada controller manager
    shell: "{{ bin_dir }}/kubectl apply -f {{ karmada_controlplane_manifests }}/{{ item.item.file }}"  # noqa 301 306 303 305
    ignore_errors: true
    with_items: "{{ karmada_host_manifests.results }}"

  - name: Set status karmada Runing
    vars:
      karmada_status: "Running"
    k8s_status:
      api_version: operator.karmada.io/v1alpha1
      kind: KarmadaDeployment
      name: "{{ karmada_cluster_name }}"
      namespace: "{{ karmada_namespace }}"
      status: "{{ lookup('template', 'status.yaml') | from_yaml }}"

  - name: Get karmada-apiserver ipaddres
    shell: "{{ bin_dir }}/kubectl get svc karmada-apiserver -n {{ karmada_namespace }} -o jsonpath='{.spec.clusterIP}'"
    register: apiserver_ip

  - name: Set fact of karmada-apiserver ipaddress
    set_fact:
      karmada_apiserver_ip: "{{ apiserver_ip.stdout }}"

  - name: force delete install kubeconfig job
    k8s:
      state: "absent"
      definition: "{{ lookup('template', 'karmada_config_job.yaml') | from_yaml }}"
    ignore_errors: true

  - name: Create karmada-apiserver admin kubeconfig on host cluster
    k8s:
      state: "present"
      definition: "{{ lookup('template', 'karmada_config_job.yaml') | from_yaml }}"

  when: karmada_cluster_phase == "new"

# todo(riverzhang)
# logic for scale、upgrade